{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d463f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell, then restart kernel\n",
    "!pip install -qq botocore --upgrade --user\n",
    "!pip install -qq boto3 --upgrade --user\n",
    "!pip install -qq awscli --upgrade --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723f24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run this cell after restarting kernel\n",
    "!pip install -qq sagemaker --upgrade\n",
    "!pip install -qq torch --upgrade\n",
    "!pip install -qq sagemaker-huggingface-inference-toolkit \n",
    "!pip install -qq transformers \"datasets[s3]\"\n",
    "!pip install -qq ipywidgets\n",
    "!pip install -qq watermark \n",
    "!pip install -qq seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315192c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import ProfilerConfig, DebuggerHookConfig, Rule, ProfilerRule, rule_configs\n",
    "import sagemaker.huggingface\n",
    "from sagemaker.huggingface import HuggingFace\n",
    "import transformers\n",
    "from transformers import RobertaConfig, RobertaModel, RobertaTokenizer, RobertaForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset, load_dataset, load_dataset_builder, load_metric\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from textwrap import wrap\n",
    "\n",
    "import boto3\n",
    "import pprint\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ead973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up sagemaker session\n",
    "sess = sagemaker.Session()\n",
    "sagemaker_session_bucket=None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    # set to default bucket if a bucket name is not given\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a710e04",
   "metadata": {},
   "source": [
    "# Finetune RoBERTa to predict virality scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e833f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create RoBERTa tokenizer\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "# load data\n",
    "data_path = \"RoBERTa/data\"\n",
    "train_path = data_path + \"/train_tweets.csv\"\n",
    "data = load_dataset(\"csv\", data_files=train_path) #, features=features)\n",
    "data = data['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f299ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer helper function\n",
    "def tokenize(batch):\n",
    "    return tokenizer(batch['Text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2bd764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign virality score to labels column\n",
    "virality_score_label = \"ViralityScoreSimple_NormalizedByUserMedian\"\n",
    "def assign_virality_label(example):\n",
    "    example[\"labels\"] = example[virality_score_label]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d095d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign viral (1) vs. not viral (0) labels\n",
    "labeled_data = data.map(assign_virality_label)\n",
    "\n",
    "# tokenize data\n",
    "tokenized_data = labeled_data.map(tokenize, batched=True)\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "'''\n",
    "# FOR PROTOTYPING: only use first 1000 examples\n",
    "proto_tokenized_data = tokenized_data.shuffle(seed=42).select(range(1000))\n",
    "proto_split_data = proto_tokenized_data.train_test_split(test_size=test_size, shuffle=True)\n",
    "# get training set\n",
    "proto_train_data = proto_split_data['train']\n",
    "# split again into validation and test sets\n",
    "proto_valid_test_data = proto_split_data['test'].train_test_split(test_size=0.5)\n",
    "# get validation set\n",
    "proto_valid_data = proto_valid_test_data['train']\n",
    "# get test set\n",
    "proto_test_data = proto_valid_test_data['test']\n",
    "'''\n",
    "\n",
    "# split data into train and test sets\n",
    "split_data = tokenized_data.train_test_split(test_size=test_size, shuffle=True)\n",
    "# get training set\n",
    "train_data = split_data['train']\n",
    "# split again into validation and test sets\n",
    "valid_test_data = split_data['test'].train_test_split(test_size=0.5)\n",
    "# get validation set\n",
    "valid_data = valid_test_data['train']\n",
    "# get test set\n",
    "test_data = valid_test_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fba123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format train data to pytorch\n",
    "train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "#proto_train_data.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bf8253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76a38ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"mse\")\n",
    "\n",
    "learning_rates = [5e-6, 1e-5, 2e-5, 5e-5]\n",
    "errors = []\n",
    "strategy = \"epoch\"\n",
    "\n",
    "# training loop to optimize learning rate and epochs\n",
    "for lr in learning_rates:\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1) \n",
    "    model.to(torch.device(\"cuda\"))\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=\"test_trainer\", \n",
    "        evaluation_strategy=strategy,\n",
    "        save_strategy=strategy,\n",
    "        logging_strategy=strategy,\n",
    "        num_train_epochs=4,\n",
    "        learning_rate=lr,\n",
    "        load_best_model_at_end=True\n",
    "    )\n",
    "    \n",
    "    trainer = Trainer(\n",
    "        model = model,\n",
    "        args = training_args,\n",
    "        train_dataset = train_data,\n",
    "        eval_dataset = valid_data,\n",
    "        compute_metrics = compute_metrics,\n",
    "        tokenizer = tokenizer \n",
    "    )\n",
    "        \n",
    "    trainer.train()\n",
    "    \n",
    "    prediction = trainer.predict(test_data)\n",
    "    test_mse = prediction.metrics['test_mse']\n",
    "    errors.append(test_mse)\n",
    "    \n",
    "    model_name = \"RoBERTa/test_trainer/model_\" + virality_score_label + \"_lr={lr:.0e}_mse={mse:.2f}\".format(lr=lr, mse=test_mse)\n",
    "    trainer.save_model(model_name)\n",
    "    \n",
    "    # remove test trainer checkpoint files\n",
    "    !rm RoBERTa/test_trainer/checkpoint* -r\n",
    "    \n",
    "# plot mse vs learning rate\n",
    "plt.plot(learning_rates, errors)\n",
    "plt.title(virality_score_label + \" Test MSE vs. Learning Rate\")\n",
    "plt.xlabel(\"learning rate\")\n",
    "plt.ylabel(\"test MSE\")\n",
    "plt.savefig(virality_score_label + \"lr_mse.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c971a990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ViralityScoreSimple_NormalizedByTotalMedian\n",
    "'''\n",
    "learning_rates = [1e-5, 2e-5, 5e-5, 7.5e-5]\n",
    "train_loss = [\n",
    "    [1.715500, 1.228800, 0.928500, 0.736600],\n",
    "    [1.747900, 1.203900, 0.839400, 0.589900],\n",
    "    [1.933000, 1.410100, 1.011000, 0.671400],\n",
    "    [2.499100, 2.488200, 2.478800, 2.472800]\n",
    "]\n",
    "valid_loss = [\n",
    "    [1.510489, 1.409851, 1.378049, 1.414043],\n",
    "    [1.525817, 1.356487, 1.363454, 1.402772],\n",
    "    [1.673826, 1.530528, 1.436984, 1.508058],\n",
    "    [2.532647, 2.521519, 2.522391, 2.521056]\n",
    "]\n",
    "'''\n",
    "\n",
    "# ViralityScore_NormalizedByTotalMedian\n",
    "'''\n",
    "learning_rates = [5e-6, 1e-5, 2e-5, 5e-5]\n",
    "train_loss = [\n",
    "    [5.450600, 4.203500, 3.504400, 3.049300],\n",
    "    [5.726000, 4.355900, 3.087100, 2.049400],\n",
    "    [5.323100, 3.690800, 2.531000, 1.768400],\n",
    "    [5.291800, 3.827100, 2.880200, 2.262100]\n",
    "]\n",
    "\n",
    "valid_loss = [\n",
    "    [4.612507, 4.545609, 4.314688, 4.399825],\n",
    "    [4.887200, 5.360254, 4.226186, 4.526827],\n",
    "    [4.468752, 3.904405, 4.267315, 4.452236],\n",
    "    [4.407519, 3.944263, 4.117460, 4.215764]\n",
    "]\n",
    "'''\n",
    "\n",
    "# ViralityScoreSimple_NormalizedByUserMedian\n",
    "'''\n",
    "learning_rates = [5e-6, 1e-5, 2e-5, 5e-5]\n",
    "train_loss = [\n",
    "    [1.112900, 0.924700, 0.801000, 0.724600],\n",
    "    [1.107500, 0.872100, 0.687500, 0.558400],\n",
    "    [1.122800, 0.867100, 0.631600, 0.462400],\n",
    "    [1.419700, 1.435200, 1.431000, 1.424700]\n",
    "]\n",
    "valid_loss = [\n",
    "    [0.984366, 1.005421, 0.964301, 0.999405],\n",
    "    [0.976736, 0.989782, 0.984413, 1.027293],\n",
    "    [0.985014, 0.965548, 0.974290, 1.044437],\n",
    "    [1.357621, 1.361440, 1.355929, 1.355403]\n",
    "]\n",
    "'''\n",
    "\n",
    "# ViralityScore_NormalizedByUserMedian\n",
    "learning_rates = [5e-6, 1e-5, 2e-5, 5e-5]\n",
    "train_loss = [\n",
    "    [1.174900, 0.974600, 0.850300, 0.760900],\n",
    "    [1.157500, 0.906400, 0.716000, 0.583700],\n",
    "    [1.177500, 0.891400, 0.637400, 0.456100],\n",
    "    [1.479400, 1.469800, 1.467100, 1.459600]\n",
    "]\n",
    "valid_loss = [\n",
    "    [1.020328, 1.014788, 0.992721, 1.031842],\n",
    "    [0.995074, 0.991157, 1.026172, 1.059588],\n",
    "    [0.992120, 0.970083, 1.003705, 1.049842],\n",
    "    [1.469030, 1.469516, 1.468846, 1.469292]\n",
    "]\n",
    "\n",
    "epochs = [1, 2, 3, 4]\n",
    "colors = ['r', 'c', 'y', 'm']\n",
    "\n",
    "fig = plt.figure(1)\n",
    "for i in range(4):\n",
    "    lr = learning_rates[i]\n",
    "    color = colors[i]\n",
    "    plt.plot(epochs, train_loss[i], linestyle='-', color=color, label=\"lr={:.0e} train\".format(lr))\n",
    "    plt.plot(epochs, valid_loss[i], linestyle=':', color=color, label=\"lr={:.0e} valid\".format(lr))\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05,0.8))\n",
    "plt.title(\"Loss over training epochs for virality score norm. by user median\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()\n",
    "fig.savefig(\"./virality_pred_fig/\" + virality_score_label + \"_training_loss\".format(lr), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e709951e",
   "metadata": {},
   "source": [
    "# Predict virality scores of tweets generated by GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda6ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"mse\")\n",
    "strategy = \"epoch\"\n",
    "\n",
    "# load best model\n",
    "best_model_filename = \"RoBERTa/test_trainer/model_ViralityScoreSimple_NormalizedByUserMedian_lr=2e-05_mse=1.02\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(best_model_filename)\n",
    "model.to(torch.device(\"cuda\"))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=strategy,\n",
    "    save_strategy=strategy,\n",
    "    logging_strategy=strategy,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_data,\n",
    "    eval_dataset = valid_data,\n",
    "    compute_metrics = compute_metrics,\n",
    "    tokenizer = tokenizer \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62d995b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_nonviral_twts_file = \"RoBERTa/data/dem_nonviral.txt\"\n",
    "dem_viral_twts_file = \"RoBERTa/data/dem_viral.txt\"\n",
    "rep_nonviral_twts_file = \"RoBERTa/data/rep_nonviral.txt\"\n",
    "rep_viral_twts_file = \"RoBERTa/data/rep_viral.txt\"\n",
    "gen_data_folder = \"RoBERTa/gen_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f3d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# clean up gpt generated tweets\n",
    "\n",
    "with open(dem_nonviral_twts_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    text = text.replace(\"<BOS>\", \"\")\n",
    "    text = text.replace(\"<|endoftext|>\", \"\")\n",
    "    text = re.split(r'=== GENERATED SEQUENCE [0-9]{1,3} ===', text)\n",
    "    dem_nonviral_twts = text[1:]\n",
    "for i in range(len(dem_nonviral_twts)):\n",
    "    dem_nonviral_twts[i] = dem_nonviral_twts[i].strip()\n",
    "    \n",
    "with open(dem_viral_twts_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    text = text.replace(\"<BOS>\", \"\")\n",
    "    text = text.replace(\"<|endoftext|>\", \"\")\n",
    "    text = re.split(r'=== GENERATED SEQUENCE [0-9]{1,3} ===', text)\n",
    "    dem_viral_twts = text[1:]\n",
    "for i in range(len(dem_viral_twts)):\n",
    "    dem_viral_twts[i] = dem_viral_twts[i].strip()\n",
    "    \n",
    "with open(rep_nonviral_twts_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    text = text.replace(\"<BOS>\", \"\")\n",
    "    text = text.replace(\"<|endoftext|>\", \"\")\n",
    "    text = re.split(r'=== GENERATED SEQUENCE [0-9]{1,3} ===', text)\n",
    "    rep_nonviral_twts = text[1:]\n",
    "for i in range(len(rep_nonviral_twts)):\n",
    "    rep_nonviral_twts[i] = rep_nonviral_twts[i].strip()\n",
    "    \n",
    "with open(rep_viral_twts_file, 'r') as file:\n",
    "    text = file.read()\n",
    "    text = text.replace(\"<BOS>\", \"\")\n",
    "    text = text.replace(\"<|endoftext|>\", \"\")\n",
    "    text = re.split(r'=== GENERATED SEQUENCE [0-9]{1,3} ===', text)\n",
    "    rep_viral_twts = data[1:]\n",
    "for i in range(len(rep_viral_twts)):\n",
    "    rep_viral_twts[i] = rep_viral_twts[i].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994bc929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_nonviral_df = pd.DataFrame()\n",
    "dem_nonviral_df.insert(0, \"Text\", dem_nonviral_twts)\n",
    "dem_nonviral_data = Dataset.from_pandas(dem_nonviral_df)\n",
    "\n",
    "dem_viral_df = pd.DataFrame()\n",
    "dem_viral_df.insert(0, \"Text\", dem_viral_twts)\n",
    "dem_viral_data = Dataset.from_pandas(dem_viral_df)\n",
    "\n",
    "rep_nonviral_df = pd.DataFrame()\n",
    "rep_nonviral_df.insert(0, \"Text\", rep_nonviral_twts)\n",
    "rep_nonviral_data = Dataset.from_pandas(rep_nonviral_df)\n",
    "\n",
    "rep_viral_df = pd.DataFrame()\n",
    "rep_viral_df.insert(0, \"Text\", rep_viral_twts)\n",
    "rep_viral_data = Dataset.from_pandas(rep_viral_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379016b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dem_nonviral_data = dem_nonviral_data.map(tokenize, batched=True)\n",
    "tokenized_dem_viral_data = dem_viral_data.map(tokenize, batched=True)\n",
    "tokenized_rep_nonviral_data = rep_nonviral_data.map(tokenize, batched=True)\n",
    "tokenized_rep_viral_data = rep_viral_data.map(tokenize, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute virality score predictions\n",
    "dem_nonviral_preds = trainer.predict(tokenized_dem_nonviral_data)\n",
    "dem_viral_preds = trainer.predict(tokenized_dem_viral_data)\n",
    "rep_nonviral_preds = trainer.predict(tokenized_rep_nonviral_data)\n",
    "rep_viral_preds = trainer.predict(tokenized_rep_viral_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f200ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predicted scores\n",
    "from numpy import savetxt\n",
    "savetxt(gen_data_folder + 'dem_nonviral_preds.txt', dem_nonviral_preds.predictions)\n",
    "savetxt(gen_data_folder + 'dem_viral_preds.txt', dem_viral_preds.predictions)\n",
    "savetxt(gen_data_folder + 'rep_nonviral_preds.txt', rep_nonviral_preds.predictions)\n",
    "savetxt(gen_data_folder + 'rep_viral_preds.txt', rep_viral_preds.predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c82486",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_nonviral_avg = np.mean(dem_nonviral_preds.predictions)\n",
    "dem_viral_avg = np.mean(dem_viral_preds.predictions)\n",
    "dem_nonviral_med = np.median(dem_nonviral_preds.predictions)\n",
    "dem_viral_med = np.median(dem_viral_preds.predictions)\n",
    "print(\"dem mean:\", dem_nonviral_avg, dem_viral_avg)\n",
    "print(\"dem median:\", dem_nonviral_med, dem_viral_med)\n",
    "\n",
    "rep_nonviral_avg = np.mean(rep_nonviral_preds.predictions)\n",
    "rep_viral_avg = np.mean(rep_viral_preds.predictions)\n",
    "rep_nonviral_med = np.median(rep_nonviral_preds.predictions)\n",
    "rep_viral_med = np.median(rep_viral_preds.predictions)\n",
    "print(\"rep mean:\", rep_nonviral_avg, rep_viral_avg)\n",
    "print(\"rep median:\", rep_nonviral_med, rep_viral_med)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00aed635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores for democratic tweets\n",
    "fig = plt.figure(1)\n",
    "plt.scatter(dem_nonviral_preds.predictions, np.repeat(-1,100), color='m', marker='.', label=\"nonviral\")\n",
    "plt.scatter(dem_viral_preds.predictions, np.repeat(1,100), color='c', marker='.', label=\"viral\")\n",
    "plt.legend()\n",
    "plt.ylim([-4,4])\n",
    "plt.title(\"Virality score predictions for generated Democratic tweets\")\n",
    "plt.xlabel(\"virality score\")\n",
    "plt.ylabel(\"training set virality (true/false)\")\n",
    "fig.savefig(gen_data_folder + \"dem_tweets_bool.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d94556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot scores for republican tweets\n",
    "fig = plt.figure(1)\n",
    "plt.scatter(rep_viral_preds.predictions, np.repeat(1,100), color='c', marker='.', label=\"viral\")\n",
    "plt.scatter(rep_nonviral_preds.predictions, np.repeat(-1,100), color='m', marker='.', label=\"nonviral\")\n",
    "plt.legend()\n",
    "plt.ylim([-4,4])\n",
    "plt.title(\"Virality score predictions for generated Republican tweets\")\n",
    "plt.xlabel(\"virality score\")\n",
    "plt.ylabel(\"training set virality (true/false)\")\n",
    "fig.savefig(gen_data_folder + \"gen_data/rep_tweets_bool.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e25530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get top 10 most viral and bottom 10 least viral tweets for each party\n",
    "top_10_viral_dem = np.argsort(np.reshape(dem_viral_preds.predictions, -1))[::-1][:10]\n",
    "bot_10_viral_dem = np.argsort(np.reshape(dem_nonviral_preds.predictions, -1))[:10]\n",
    "top_10_viral_rep = np.argsort(np.reshape(rep_viral_preds.predictions, -1))[::-1][:10]\n",
    "bot_10_viral_rep = np.argsort(np.reshape(rep_nonviral_preds.predictions, -1))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ac9d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_10_viral_dem_twts = [None] * 10\n",
    "bot_10_viral_dem_twts = [None] * 10\n",
    "top_10_viral_rep_twts = [None] * 10\n",
    "bot_10_viral_rep_twts = [None] * 10\n",
    "\n",
    "for i in range(10):\n",
    "    top_10_viral_dem_twts[i] = dem_viral_twts[top_10_viral_dem[i]]\n",
    "    bot_10_viral_dem_twts[i] = dem_nonviral_twts[bot_10_viral_dem[i]]\n",
    "    top_10_viral_rep_twts[i] = rep_viral_twts[top_10_viral_rep[i]]\n",
    "    bot_10_viral_rep_twts[i] = rep_nonviral_twts[bot_10_viral_rep[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c642434f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tweets\n",
    "with open(gen_data_folder + 'top_dem_twts.txt', 'w') as f:\n",
    "    for tweet in top_10_viral_dem_twts:\n",
    "        f.write(\"%s\\n\\n\" % tweet)\n",
    "        \n",
    "with open(gen_data_folder + 'bot_dem_twts.txt', 'w') as f:\n",
    "    for tweet in bot_10_viral_dem_twts:\n",
    "        f.write(\"%s\\n\\n\" % tweet)\n",
    "        \n",
    "with open(gen_data_folder + 'top_rep_twts.txt', 'w') as f:\n",
    "    for tweet in top_10_viral_rep_twts:\n",
    "        f.write(\"%s\\n\\n\" % tweet)\n",
    "        \n",
    "with open(gen_data_folder + 'bot_rep_twts.txt', 'w') as f:\n",
    "    for tweet in bot_10_viral_rep_twts:\n",
    "        f.write(\"%s\\n\\n\" % tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d18cfc",
   "metadata": {},
   "source": [
    "# Finetune RoBERTa to classify party affiliation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316d558e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_party_label(example):\n",
    "    # 0 = democrat, 1 = republican\n",
    "    example[\"labels\"] = int(example[\"Party\"] == \"republican\")\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b9821",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_party_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return party_metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b48e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign party labels\n",
    "labeled_party_data = data.map(assign_party_label)\n",
    "\n",
    "# tokenize data\n",
    "tokenized_party_data = labeled_party_data.map(tokenize, batched=True)\n",
    "\n",
    "# split data into train and test sets\n",
    "split_party_data = tokenized_party_data.train_test_split(test_size=test_size, shuffle=True)\n",
    "# get training set\n",
    "train_party_data = split_party_data['train']\n",
    "# split again into validation and test sets\n",
    "valid_test_party_data = split_party_data['test'].train_test_split(test_size=0.5)\n",
    "# get validation set\n",
    "valid_party_data = valid_test_party_data['train']\n",
    "# get test set\n",
    "test_party_data = valid_test_party_data['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36090db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_party_data.set_format('torch', columns=['input_ids', 'attention_mask', 'labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50418b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "party_metric = load_metric(\"f1\")\n",
    "\n",
    "lr = 2e-5\n",
    "strategy = \"epoch\"\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2) \n",
    "model.to(torch.device(\"cuda\"))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=strategy,\n",
    "    save_strategy=strategy,\n",
    "    logging_strategy=strategy,\n",
    "    num_train_epochs=4,\n",
    "    learning_rate=lr,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_party_data,\n",
    "    eval_dataset = valid_party_data,\n",
    "    compute_metrics = compute_party_metrics,\n",
    "    tokenizer = tokenizer \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113fe3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = trainer.predict(test_party_data)\n",
    "test_f1 = prediction.metrics['test_f1']\n",
    "\n",
    "model_name = \"RoBERTa/test_trainer/model_party_lr={lr:.0e}_f1={f1:.2f}\".format(lr=lr, f1=test_f1)\n",
    "trainer.save_model(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112e86ea",
   "metadata": {},
   "source": [
    "# Predict party affiliation for tweets generated by GPT-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7454304",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"f1\")\n",
    "strategy = \"epoch\"\n",
    "\n",
    "# load best model\n",
    "best_party_model_filename = \"RoBERTa/test_trainer/model_party_lr=2e-05_f1=0.90\"\n",
    "model = RobertaForSequenceClassification.from_pretrained(best_party_model_filename)\n",
    "model.to(torch.device(\"cuda\"))\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\", \n",
    "    evaluation_strategy=strategy,\n",
    "    save_strategy=strategy,\n",
    "    logging_strategy=strategy,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-5,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_party_data,\n",
    "    eval_dataset = valid_party_data,\n",
    "    compute_metrics = compute_party_metrics,\n",
    "    tokenizer = tokenizer \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a7128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_logits_to_class(logits):\n",
    "    return np.argmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8df30e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict party affiliations\n",
    "dem_nonviral_party_preds = trainer.predict(tokenized_dem_nonviral_data).predictions\n",
    "dem_viral_party_preds = trainer.predict(tokenized_dem_viral_data).predictions\n",
    "rep_nonviral_party_preds = trainer.predict(tokenized_rep_nonviral_data).predictions\n",
    "rep_viral_party_preds = trainer.predict(tokenized_rep_viral_data).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7008b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dem_nonviral_party_class = np.apply_along_axis(convert_logits_to_class, 1, np.array(dem_nonviral_party_preds))\n",
    "dem_viral_party_class = np.apply_along_axis(convert_logits_to_class, 1, np.array(dem_viral_party_preds))\n",
    "rep_nonviral_party_class = np.apply_along_axis(convert_logits_to_class, 1, np.array(rep_nonviral_party_preds))\n",
    "rep_viral_party_class = np.apply_along_axis(convert_logits_to_class, 1, np.array(rep_viral_party_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3e8db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save party predictions\n",
    "from numpy import savetxt\n",
    "savetxt(gen_data_folder + 'dem_nonviral_party_preds.txt', dem_nonviral_party_class)\n",
    "savetxt(gen_data_folder + 'dem_viral_party_preds.txt', dem_viral_party_class)\n",
    "savetxt(gen_data_folder + 'rep_nonviral_party_preds.txt', rep_nonviral_party_class)\n",
    "savetxt(gen_data_folder + 'rep_viral_party_preds.txt', rep_viral_party_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfa6e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate f1 of predictions for generated tweets\n",
    "\n",
    "dem_viral_tp = 0\n",
    "dem_viral_fp = np.sum(dem_viral_party_class == 1)\n",
    "dem_viral_tn = np.sum(dem_viral_party_class == 0)\n",
    "dem_viral_fn = 0\n",
    "\n",
    "dem_nonviral_tp = 0\n",
    "dem_nonviral_fp = np.sum(dem_nonviral_party_class == 1)\n",
    "dem_nonviral_tn = np.sum(dem_nonviral_party_class == 0)\n",
    "dem_nonviral_fn = 0\n",
    "\n",
    "rep_viral_tp = np.sum(rep_viral_party_class == 1)\n",
    "rep_viral_fp = 0\n",
    "rep_viral_tn = 0\n",
    "rep_viral_fn = np.sum(rep_viral_party_class == 0)\n",
    "\n",
    "rep_nonviral_tp = np.sum(rep_nonviral_party_class == 1)\n",
    "rep_nonviral_fp = 0\n",
    "rep_nonviral_tn = 0\n",
    "rep_nonviral_fn = np.sum(rep_nonviral_party_class == 0)\n",
    "\n",
    "tp = dem_viral_tp + dem_nonviral_tp + rep_viral_tp + rep_nonviral_tp\n",
    "fp = dem_viral_fp + dem_nonviral_fp + rep_viral_fp + rep_nonviral_fp\n",
    "tn = dem_viral_tn + dem_nonviral_tn + rep_viral_tn + rep_nonviral_tn\n",
    "fn = dem_viral_fn + dem_nonviral_fn + rep_viral_fn + rep_nonviral_fn\n",
    "\n",
    "# recall = true positive / (true positive + false negative)\n",
    "recall = tp / (tp + fn)\n",
    "# precision = true positive / (true positive + false positive)\n",
    "precision = tp / (tp + fp)\n",
    "f1 = 2 / (1 / recall + 1 / precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c031dfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tp, fp, tn, fn, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30283a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

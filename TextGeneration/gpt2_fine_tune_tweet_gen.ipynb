{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "J-n7g4-19D-v"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install -U gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_LuHSuAaAs8",
        "outputId": "0ffbd657-e446-465e-8c87-a7be1b8f1693"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 19.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 10.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 30 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 40 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 51 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 81 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 92 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 102 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 112 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 122 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 133 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 143 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 153 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 163 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 174 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 184 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 194 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 204 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 215 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 225 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 235 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 245 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 256 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 266 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 276 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 286 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 296 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 307 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 317 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 325 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 46.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Collecting huggingface-hub<1.0.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 50.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.13)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.2 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 48.7 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: multidict, frozenlist, yarl, urllib3, asynctest, async-timeout, aiosignal, fsspec, aiohttp, xxhash, responses, huggingface-hub, datasets\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 datasets-2.1.0 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 multidict-6.0.2 responses-0.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcS6tc2zJhTC",
        "outputId": "16cb4d5c-76fa-4f3e-f6f4-750cd1c94cc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-2benwdi7\n",
            "  Running command git clone -q https://github.com/huggingface/transformers.git /tmp/pip-req-build-2benwdi7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (4.11.3)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 36.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (1.21.6)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.19.0.dev0) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.19.0.dev0) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.19.0.dev0) (3.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.19.0.dev0) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.19.0.dev0) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.19.0.dev0) (7.1.2)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.19.0.dev0-py3-none-any.whl size=4040857 sha256=293db174cb46bad896713220c3fbb86dbc865ad7527c7ced5127aeca3104dc01\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-p94i531j/wheels/90/a5/44/6bcd83827c8a60628c5ad602f429cd5076bcce5f2a90054947\n",
            "Successfully built transformers\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.19.0.dev0\n"
          ]
        }
      ],
      "source": [
        "# ! pip install transformers datasets\n",
        "! pip install git+https://github.com/huggingface/transformers.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SQMwFja98Sn",
        "outputId": "87184d6a-151f-4c95-df64-adbada9be75d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1C_K5ISCSmSQVU2uFDBhS5LomQqtCtjJu\n",
            "To: /content/Tweets.csv\n",
            "\r  0% 0.00/7.54M [00:00<?, ?B/s]\r100% 7.54M/7.54M [00:00<00:00, 77.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown 1C_K5ISCSmSQVU2uFDBhS5LomQqtCtjJu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NPdorrOf-PDI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2WlZipwz-gxk"
      },
      "outputs": [],
      "source": [
        "tweets = pd.read_csv('/content/Tweets.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRP7Ofkd8NhZ",
        "outputId": "4c27e7c8-1b98-42f9-c0c2-5762511e9496"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ScreenName', 'Party', 'Text', 'ViralityScore_NormalizedByUserMedian',\n",
              "       'ViralityScoreSimple_NormalizedByUserMedian',\n",
              "       'ViralityScore_NormalizedByTotalMedian',\n",
              "       'ViralityScoreSimple_NormalizedByTotalMedian'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "tweets.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uo42-Qtt-Cp",
        "outputId": "7fc6f1d3-3103-4688-8a31-85c456cb8996"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.004253540564894"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "np.percentile(tweets.ViralityScore_NormalizedByTotalMedian, 66)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq_soqOowukp",
        "outputId": "a7cdcdd7-1095-4da4-c859-474b923276ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.1481126437509244"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "np.percentile(tweets.ViralityScore_NormalizedByTotalMedian, 33)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MeFZGE0dT1Tm"
      },
      "outputs": [],
      "source": [
        "rep_tweets = tweets[tweets.Party == 'republican']\n",
        "dem_tweets = tweets[tweets.Party == 'democrat']\n",
        "\n",
        "rep_viral_tweets = rep_tweets[rep_tweets.ViralityScoreSimple_NormalizedByUserMedian > 1.004253540564894]\n",
        "rep_nonviral_tweets = rep_tweets[rep_tweets.ViralityScoreSimple_NormalizedByUserMedian < -1.1481126437509244]\n",
        "\n",
        "dem_viral_tweets = dem_tweets[dem_tweets.ViralityScoreSimple_NormalizedByUserMedian > 1.004253540564894]\n",
        "dem_nonviral_tweets = dem_tweets[dem_tweets.ViralityScoreSimple_NormalizedByUserMedian < -1.1481126437509244]\n",
        "\n",
        "\n",
        "rep_viral_tweets_impt = rep_viral_tweets.loc[      : ,['Text', 'ViralityScoreSimple_NormalizedByUserMedian']]\n",
        "dem_viral_tweets_impt = dem_viral_tweets.loc[      : ,['Text', 'ViralityScoreSimple_NormalizedByUserMedian']]\n",
        "rep_nonviral_tweets_impt = rep_nonviral_tweets.loc[: ,['Text', 'ViralityScoreSimple_NormalizedByUserMedian']]\n",
        "dem_nonviral_tweets_impt = dem_nonviral_tweets.loc[: ,['Text', 'ViralityScoreSimple_NormalizedByUserMedian']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YxfufDjJYQxv"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "rep_viral_full_train, rep_viral_df_test = train_test_split(rep_viral_tweets_impt, test_size=0.2)\n",
        "rep_viral_df_train, rep_viral_df_valid = train_test_split(rep_viral_full_train, test_size = 0.2)\n",
        "\n",
        "dem_viral_full_train, dem_viral_df_test = train_test_split(dem_viral_tweets_impt, test_size=0.2)\n",
        "dem_viral_df_train, dem_viral_df_valid = train_test_split(dem_viral_full_train, test_size = 0.2)\n",
        "\n",
        "dem_nonviral_full_train, dem_nonviral_df_test = train_test_split(dem_nonviral_tweets_impt, test_size=0.2)\n",
        "dem_nonviral_df_train, dem_nonviral_df_valid = train_test_split(dem_nonviral_full_train, test_size = 0.2)\n",
        "\n",
        "rep_nonviral_full_train, rep_nonviral_df_test = train_test_split(rep_nonviral_tweets_impt, test_size=0.2)\n",
        "rep_nonviral_df_train, rep_nonviral_df_valid = train_test_split(rep_nonviral_full_train, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8xnNyUbZ1KRJ"
      },
      "outputs": [],
      "source": [
        "def build_dataset(df, dest_path):\n",
        "    with open(dest_path, 'w') as f:  \n",
        "      data = ''\n",
        "      texts = df['Text'].tolist()\n",
        "      for t in texts:\n",
        "          bos_token = '<BOS>'\n",
        "          eos_token = '<EOS>'\n",
        "          data += bos_token + ' ' + t + ' ' + eos_token + '\\n'\n",
        "          \n",
        "      f.write(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zhaCyGSV1xqR"
      },
      "outputs": [],
      "source": [
        "!rm -rf 'rep_viral'\n",
        "!rm -rf 'rep_nonviral'\n",
        "!rm -rf 'dem_viral'\n",
        "!rm -rf 'dem_nonviral'\n",
        "\n",
        "!mkdir 'rep_viral'\n",
        "!mkdir 'rep_nonviral'\n",
        "!mkdir 'dem_viral'\n",
        "!mkdir 'dem_nonviral'\n",
        "\n",
        "build_dataset(rep_viral_df_train, 'rep_viral/rep_viral_train.txt')\n",
        "build_dataset(rep_viral_df_valid, 'rep_viral/rep_viral_valid.txt')\n",
        "build_dataset(rep_viral_df_test, 'rep_viral/rep_viral_test.txt')\n",
        "\n",
        "build_dataset(dem_viral_df_train, 'dem_viral/dem_viral_train.txt')\n",
        "build_dataset(dem_viral_df_valid, 'dem_viral/dem_viral_valid.txt')\n",
        "build_dataset(dem_viral_df_test,  'dem_viral/dem_viral_test.txt')\n",
        "\n",
        "build_dataset(dem_nonviral_df_train, 'dem_nonviral/dem_nonviral_train.txt')\n",
        "build_dataset(dem_nonviral_df_valid, 'dem_nonviral/dem_nonviral_valid.txt')\n",
        "build_dataset(dem_nonviral_df_test,  'dem_nonviral/dem_nonviral_test.txt')\n",
        "\n",
        "build_dataset(rep_nonviral_df_train, 'rep_nonviral/rep_nonviral_train.txt')\n",
        "build_dataset(rep_nonviral_df_valid, 'rep_nonviral/rep_nonviral_valid.txt')\n",
        "build_dataset(rep_nonviral_df_test,  'rep_nonviral/rep_nonviral_test.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LwcpLXcnkbpv",
        "outputId": "701c56ae-c359-4cdb-fe54-593e5b55ed9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dem_nonviral  dem_viral  rep_nonviral  rep_viral  sample_data  Tweets.csv\n"
          ]
        }
      ],
      "source": [
        "!ls '/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TpeBuxIoZVMF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "cuda = torch.device('cuda')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC7cDXvVygnA",
        "outputId": "2c952a49-3717-485b-f475-155ebc452e03",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: N=1\n",
            "env: OUTPUT_DIR=/content/dem_viral_five_iter/\n",
            "env: TRAIN_FILE=/content/dem_viral/dem_viral_train.txt\n",
            "env: VALID_FILE=/content/dem_viral/dem_viral_valid.txt\n",
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "python3: can't open file 'run_clm.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !ls '/content'\n",
        "\n",
        "%env N=1\n",
        "%env OUTPUT_DIR=/content/dem_viral_five_iter/\n",
        "%env TRAIN_FILE=/content/dem_viral/dem_viral_train.txt\n",
        "%env VALID_FILE=/content/dem_viral/dem_viral_valid.txt\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "!python run_clm.py \\\n",
        "--output_dir=$OUTPUT_DIR \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=gpt2 \\\n",
        "--dataset_name='dem_viral' \\\n",
        "--do_train \\\n",
        "--train_file=$TRAIN_FILE \\\n",
        "--do_eval \\\n",
        "--validation_file=$VALID_FILE \\\n",
        "--per_device_train_batch_size=2 \\\n",
        "--per_device_eval_batch_size=2 \\\n",
        "--learning_rate 3e-5 \\\n",
        "--num_train_epochs=20 \\\n",
        "--overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7aO4TT1A4kr",
        "outputId": "523a1a15-d913-43d0-c975-bf0f09e159e3",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: N=1\n",
            "env: OUTPUT_DIR=/content/rep_viral_five_iter/\n",
            "env: TRAIN_FILE=/content/rep_viral/rep_viral_train.txt\n",
            "env: VALID_FILE=/content/rep_viral/rep_viral_valid.txt\n",
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "python3: can't open file 'run_clm.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !ls '/content'\n",
        "\n",
        "%env N=1\n",
        "%env OUTPUT_DIR=/content/rep_viral_five_iter/\n",
        "%env TRAIN_FILE=/content/rep_viral/rep_viral_train.txt\n",
        "%env VALID_FILE=/content/rep_viral/rep_viral_valid.txt\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "!python run_clm.py \\\n",
        "--output_dir=$OUTPUT_DIR \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=gpt2 \\\n",
        "--dataset_name='rep_viral' \\\n",
        "--do_train \\\n",
        "--train_file=$TRAIN_FILE \\\n",
        "--do_eval \\\n",
        "--validation_file=$VALID_FILE \\\n",
        "--per_device_train_batch_size=2 \\\n",
        "--per_device_eval_batch_size=2 \\\n",
        "--learning_rate 7e-5 \\\n",
        "--num_train_epochs=10 \\\n",
        "--overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B945uOTUaw6W",
        "outputId": "96cb7406-e7ec-4a6e-95c4-e6524ebef586"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: N=1\n",
            "env: OUTPUT_DIR=/content/rep_nonviral_five_iter/\n",
            "env: TRAIN_FILE=/content/rep_nonviral/rep_nonviral_train.txt\n",
            "env: VALID_FILE=/content/rep_nonviral/rep_nonviral_valid.txt\n",
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "python3: can't open file 'run_clm.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !ls '/content'\n",
        "\n",
        "%env N=1\n",
        "%env OUTPUT_DIR=/content/rep_nonviral_five_iter/\n",
        "%env TRAIN_FILE=/content/rep_nonviral/rep_nonviral_train.txt\n",
        "%env VALID_FILE=/content/rep_nonviral/rep_nonviral_valid.txt\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "!python run_clm.py \\\n",
        "--output_dir=$OUTPUT_DIR \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=gpt2 \\\n",
        "--dataset_name='rep_nonviral' \\\n",
        "--do_train \\\n",
        "--train_file=$TRAIN_FILE \\\n",
        "--do_eval \\\n",
        "--validation_file=$VALID_FILE \\\n",
        "--per_device_train_batch_size=2 \\\n",
        "--per_device_eval_batch_size=2 \\\n",
        "--learning_rate 5e-5 \\\n",
        "--num_train_epochs=30 \\\n",
        "--overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDfmD596a9CS",
        "outputId": "7d97bf5c-af4f-4f02-e098-90e270e85606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: N=1\n",
            "env: OUTPUT_DIR=/content/dem_nonviral_five_iter/\n",
            "env: TRAIN_FILE=/content/dem_nonviral/dem_nonviral_train.txt\n",
            "env: VALID_FILE=/content/dem_nonviral/dem_nonviral_valid.txt\n",
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "python3: can't open file 'run_clm.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# !ls '/content'\n",
        "\n",
        "%env N=1\n",
        "%env OUTPUT_DIR=/content/dem_nonviral_five_iter/\n",
        "%env TRAIN_FILE=/content/dem_nonviral/dem_nonviral_train.txt\n",
        "%env VALID_FILE=/content/dem_nonviral/dem_nonviral_valid.txt\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "\n",
        "!python run_clm.py \\\n",
        "--output_dir=$OUTPUT_DIR \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=gpt2 \\\n",
        "--dataset_name='dem_nonviral' \\\n",
        "--do_train \\\n",
        "--train_file=$TRAIN_FILE \\\n",
        "--do_eval \\\n",
        "--validation_file=$VALID_FILE \\\n",
        "--per_device_train_batch_size=2 \\\n",
        "--per_device_eval_batch_size=2 \\\n",
        "--learning_rate 5e-5 \\\n",
        "--num_train_epochs=17 \\\n",
        "--overwrite_output_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GdD0UABIiPv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f5c14c-2f5e-440e-cdb1-a7de66d73652"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: OUTPUT_DIR=/content/dem_viral_five_iter/\n",
            "python3: can't open file 'run_generation.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# %env K=k_for_top-k_sampling_decoder\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env OUTPUT_DIR=/content/dem_viral_five_iter/\n",
        "\n",
        "!python run_generation.py 2>&1 \\\n",
        "--model_type gpt2 \\\n",
        "--model_name_or_path $OUTPUT_DIR \\\n",
        "--length 300 \\\n",
        "--prompt \"<BOS>\" \\\n",
        "--stop_token \"<EOS>\" \\\n",
        "--num_return_sequences 100  | tee '/content/dem_viral.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "rXQN9GTkz_Ww",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "494caeea-f6af-414f-d3a7-367f6f9ca820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: OUTPUT_DIR=/content/rep_viral_five_iter/\n",
            "python3: can't open file 'run_generation.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# %env K=k_for_top-k_sampling_decoder\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env OUTPUT_DIR=/content/rep_viral_five_iter/\n",
        "\n",
        "!python run_generation.py 2>&1 \\\n",
        "--model_type gpt2 \\\n",
        "--model_name_or_path $OUTPUT_DIR \\\n",
        "--length 300 \\\n",
        "--prompt \"<BOS>\" \\\n",
        "--stop_token \"<EOS>\" \\\n",
        "--num_return_sequences 100  | tee '/content/rep_viral.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ozHBiAOlcd-",
        "outputId": "6ec468ec-c98a-4090-831a-4c18bbe99b83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: OUTPUT_DIR=/content/dem_nonviral_five_iter/\n",
            "python3: can't open file 'run_generation.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# %env K=k_for_top-k_sampling_decoder\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env OUTPUT_DIR=/content/dem_nonviral_five_iter/\n",
        "\n",
        "!python run_generation.py 2>&1 \\\n",
        "--model_type gpt2 \\\n",
        "--model_name_or_path $OUTPUT_DIR \\\n",
        "--length 300 \\\n",
        "--prompt \"<BOS>\" \\\n",
        "--stop_token \"<EOS>\" \\\n",
        "--num_return_sequences 100  | tee '/content/dem_nonviral.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkBu8Y7LlXZR",
        "outputId": "a488bad1-dc69-4d73-f60d-96753fe07071"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: CUDA_VISIBLE_DEVICES=0\n",
            "env: OUTPUT_DIR=/content/rep_nonviral_five_iter/\n",
            "python3: can't open file 'run_generation.py': [Errno 2] No such file or directory\n"
          ]
        }
      ],
      "source": [
        "# %env K=k_for_top-k_sampling_decoder\n",
        "%env CUDA_VISIBLE_DEVICES=0\n",
        "%env OUTPUT_DIR=/content/rep_nonviral_five_iter/\n",
        "\n",
        "!python run_generation.py 2>&1 \\\n",
        "--model_type gpt2 \\\n",
        "--model_name_or_path $OUTPUT_DIR \\\n",
        "--length 300 \\\n",
        "--prompt \"<BOS>\" \\\n",
        "--stop_token \"<EOS>\" \\\n",
        "--num_return_sequences 100  | tee '/content/rep_nonviral.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L31iHXm0hZC",
        "outputId": "86070238-c44e-4fe7-89c8-93903dccd3ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/my_model_five_iter/ (stored 0%)\n",
            "  adding: content/my_model_five_iter/all_results.json (deflated 55%)\n",
            "  adding: content/my_model_five_iter/tokenizer.json (deflated 72%)\n",
            "  adding: content/my_model_five_iter/vocab.json (deflated 59%)\n",
            "  adding: content/my_model_five_iter/training_args.bin (deflated 49%)\n",
            "  adding: content/my_model_five_iter/special_tokens_map.json (deflated 38%)\n",
            "  adding: content/my_model_five_iter/README.md (deflated 50%)\n",
            "  adding: content/my_model_five_iter/pytorch_model.bin (deflated 9%)\n",
            "  adding: content/my_model_five_iter/trainer_state.json (deflated 53%)\n",
            "  adding: content/my_model_five_iter/runs/ (stored 0%)\n",
            "  adding: content/my_model_five_iter/runs/Apr17_18-30-45_f4c91529bdc1/ (stored 0%)\n",
            "  adding: content/my_model_five_iter/runs/Apr17_18-30-45_f4c91529bdc1/events.out.tfevents.1650220253.f4c91529bdc1.389.0 (deflated 57%)\n",
            "  adding: content/my_model_five_iter/runs/Apr17_18-30-45_f4c91529bdc1/events.out.tfevents.1650220625.f4c91529bdc1.389.2 (deflated 28%)\n",
            "  adding: content/my_model_five_iter/runs/Apr17_18-30-45_f4c91529bdc1/1650220253.7194607/ (stored 0%)\n",
            "  adding: content/my_model_five_iter/runs/Apr17_18-30-45_f4c91529bdc1/1650220253.7194607/events.out.tfevents.1650220253.f4c91529bdc1.389.1 (deflated 62%)\n",
            "  adding: content/my_model_five_iter/train_results.json (deflated 41%)\n",
            "  adding: content/my_model_five_iter/tokenizer_config.json (deflated 40%)\n",
            "  adding: content/my_model_five_iter/merges.txt (deflated 53%)\n",
            "  adding: content/my_model_five_iter/eval_results.json (deflated 42%)\n",
            "  adding: content/my_model_five_iter/added_tokens.json (deflated 31%)\n",
            "  adding: content/my_model_five_iter/config.json (deflated 51%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/rep_model.zip /content/my_model_five_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpqkLSsJ4F1Y",
        "outputId": "0cc64b6d-79ee-42bb-a58b-b7d1e6fc72a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/dem_viral_five_iter/ (stored 0%)\n",
            "  adding: content/dem_viral_five_iter/all_results.json (deflated 54%)\n",
            "  adding: content/dem_viral_five_iter/merges.txt (deflated 53%)\n",
            "  adding: content/dem_viral_five_iter/eval_results.json (deflated 42%)\n",
            "  adding: content/dem_viral_five_iter/config.json (deflated 51%)\n",
            "  adding: content/dem_viral_five_iter/train_results.json (deflated 40%)\n",
            "  adding: content/dem_viral_five_iter/pytorch_model.bin (deflated 9%)\n",
            "  adding: content/dem_viral_five_iter/special_tokens_map.json (deflated 38%)\n",
            "  adding: content/dem_viral_five_iter/added_tokens.json (deflated 31%)\n",
            "  adding: content/dem_viral_five_iter/tokenizer_config.json (deflated 40%)\n",
            "  adding: content/dem_viral_five_iter/training_args.bin (deflated 48%)\n",
            "  adding: content/dem_viral_five_iter/tokenizer.json (deflated 72%)\n",
            "  adding: content/dem_viral_five_iter/vocab.json (deflated 59%)\n",
            "  adding: content/dem_viral_five_iter/trainer_state.json (deflated 53%)\n",
            "  adding: content/dem_viral_five_iter/runs/ (stored 0%)\n",
            "  adding: content/dem_viral_five_iter/runs/Apr19_06-01-51_66fe1f273d70/ (stored 0%)\n",
            "  adding: content/dem_viral_five_iter/runs/Apr19_06-01-51_66fe1f273d70/events.out.tfevents.1650348402.66fe1f273d70.412.2 (deflated 28%)\n",
            "  adding: content/dem_viral_five_iter/runs/Apr19_06-01-51_66fe1f273d70/events.out.tfevents.1650348127.66fe1f273d70.412.0 (deflated 57%)\n",
            "  adding: content/dem_viral_five_iter/runs/Apr19_06-01-51_66fe1f273d70/1650348127.3829205/ (stored 0%)\n",
            "  adding: content/dem_viral_five_iter/runs/Apr19_06-01-51_66fe1f273d70/1650348127.3829205/events.out.tfevents.1650348127.66fe1f273d70.412.1 (deflated 63%)\n",
            "  adding: content/dem_viral_five_iter/README.md (deflated 49%)\n",
            "  adding: content/dem_nonviral_five_iter/ (stored 0%)\n",
            "  adding: content/dem_nonviral_five_iter/all_results.json (deflated 55%)\n",
            "  adding: content/dem_nonviral_five_iter/merges.txt (deflated 53%)\n",
            "  adding: content/dem_nonviral_five_iter/eval_results.json (deflated 42%)\n",
            "  adding: content/dem_nonviral_five_iter/config.json (deflated 51%)\n",
            "  adding: content/dem_nonviral_five_iter/train_results.json (deflated 43%)\n",
            "  adding: content/dem_nonviral_five_iter/pytorch_model.bin (deflated 9%)\n",
            "  adding: content/dem_nonviral_five_iter/special_tokens_map.json (deflated 38%)\n",
            "  adding: content/dem_nonviral_five_iter/added_tokens.json (deflated 31%)\n",
            "  adding: content/dem_nonviral_five_iter/tokenizer_config.json (deflated 40%)\n",
            "  adding: content/dem_nonviral_five_iter/training_args.bin (deflated 48%)\n",
            "  adding: content/dem_nonviral_five_iter/tokenizer.json (deflated 72%)\n",
            "  adding: content/dem_nonviral_five_iter/vocab.json (deflated 59%)\n",
            "  adding: content/dem_nonviral_five_iter/trainer_state.json (deflated 53%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/ (stored 0%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/Apr19_06-30-01_66fe1f273d70/ (stored 0%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/Apr19_06-30-01_66fe1f273d70/events.out.tfevents.1650350017.66fe1f273d70.727.2 (deflated 27%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/Apr19_06-30-01_66fe1f273d70/events.out.tfevents.1650349818.66fe1f273d70.727.0 (deflated 57%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/Apr19_06-30-01_66fe1f273d70/1650349818.4026299/ (stored 0%)\n",
            "  adding: content/dem_nonviral_five_iter/runs/Apr19_06-30-01_66fe1f273d70/1650349818.4026299/events.out.tfevents.1650349818.66fe1f273d70.727.1 (deflated 62%)\n",
            "  adding: content/dem_nonviral_five_iter/README.md (deflated 50%)\n",
            "  adding: content/rep_viral_five_iter/ (stored 0%)\n",
            "  adding: content/rep_viral_five_iter/all_results.json (deflated 55%)\n",
            "  adding: content/rep_viral_five_iter/merges.txt (deflated 53%)\n",
            "  adding: content/rep_viral_five_iter/eval_results.json (deflated 42%)\n",
            "  adding: content/rep_viral_five_iter/config.json (deflated 51%)\n",
            "  adding: content/rep_viral_five_iter/train_results.json (deflated 43%)\n",
            "  adding: content/rep_viral_five_iter/pytorch_model.bin (deflated 9%)\n",
            "  adding: content/rep_viral_five_iter/special_tokens_map.json (deflated 38%)\n",
            "  adding: content/rep_viral_five_iter/added_tokens.json (deflated 31%)\n",
            "  adding: content/rep_viral_five_iter/tokenizer_config.json (deflated 40%)\n",
            "  adding: content/rep_viral_five_iter/training_args.bin (deflated 48%)\n",
            "  adding: content/rep_viral_five_iter/tokenizer.json (deflated 72%)\n",
            "  adding: content/rep_viral_five_iter/vocab.json (deflated 59%)\n",
            "  adding: content/rep_viral_five_iter/trainer_state.json (deflated 54%)\n",
            "  adding: content/rep_viral_five_iter/runs/ (stored 0%)\n",
            "  adding: content/rep_viral_five_iter/runs/Apr19_06-07-39_66fe1f273d70/ (stored 0%)\n",
            "  adding: content/rep_viral_five_iter/runs/Apr19_06-07-39_66fe1f273d70/events.out.tfevents.1650348687.66fe1f273d70.513.2 (deflated 27%)\n",
            "  adding: content/rep_viral_five_iter/runs/Apr19_06-07-39_66fe1f273d70/events.out.tfevents.1650348475.66fe1f273d70.513.0 (deflated 57%)\n",
            "  adding: content/rep_viral_five_iter/runs/Apr19_06-07-39_66fe1f273d70/1650348475.8864672/ (stored 0%)\n",
            "  adding: content/rep_viral_five_iter/runs/Apr19_06-07-39_66fe1f273d70/1650348475.8864672/events.out.tfevents.1650348475.66fe1f273d70.513.1 (deflated 62%)\n",
            "  adding: content/rep_viral_five_iter/README.md (deflated 49%)\n",
            "  adding: content/rep_nonviral_five_iter/ (stored 0%)\n",
            "  adding: content/rep_nonviral_five_iter/all_results.json (deflated 54%)\n",
            "  adding: content/rep_nonviral_five_iter/merges.txt (deflated 53%)\n",
            "  adding: content/rep_nonviral_five_iter/eval_results.json (deflated 42%)\n",
            "  adding: content/rep_nonviral_five_iter/config.json (deflated 51%)\n",
            "  adding: content/rep_nonviral_five_iter/train_results.json (deflated 41%)\n",
            "  adding: content/rep_nonviral_five_iter/pytorch_model.bin (deflated 9%)\n",
            "  adding: content/rep_nonviral_five_iter/special_tokens_map.json (deflated 38%)\n",
            "  adding: content/rep_nonviral_five_iter/added_tokens.json (deflated 31%)\n",
            "  adding: content/rep_nonviral_five_iter/tokenizer_config.json (deflated 40%)\n",
            "  adding: content/rep_nonviral_five_iter/training_args.bin (deflated 48%)\n",
            "  adding: content/rep_nonviral_five_iter/tokenizer.json (deflated 72%)\n",
            "  adding: content/rep_nonviral_five_iter/vocab.json (deflated 59%)\n",
            "  adding: content/rep_nonviral_five_iter/trainer_state.json (deflated 53%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/ (stored 0%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/Apr19_06-21-58_66fe1f273d70/ (stored 0%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/Apr19_06-21-58_66fe1f273d70/events.out.tfevents.1650349335.66fe1f273d70.615.0 (deflated 57%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/Apr19_06-21-58_66fe1f273d70/1650349335.522093/ (stored 0%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/Apr19_06-21-58_66fe1f273d70/1650349335.522093/events.out.tfevents.1650349335.66fe1f273d70.615.1 (deflated 62%)\n",
            "  adding: content/rep_nonviral_five_iter/runs/Apr19_06-21-58_66fe1f273d70/events.out.tfevents.1650349495.66fe1f273d70.615.2 (deflated 27%)\n",
            "  adding: content/rep_nonviral_five_iter/README.md (deflated 50%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/dem_viral.zip /content/dem_viral_five_iter\n",
        "!zip -r /content/dem_nonviral.zip /content/dem_nonviral_five_iter\n",
        "!zip -r /content/rep_viral.zip /content/rep_viral_five_iter\n",
        "!zip -r /content/rep_nonviral.zip /content/rep_nonviral_five_iter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "n1jORDaem7_4",
        "outputId": "7663f7cc-4613-4e80-b686-7e7e394c391a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_b24e05c9-7e31-4226-8683-3a9deffa3c25\", \"rep_nonviral.zip\", 463631852)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_c9ebe25a-2501-4a89-858f-417ba76741be\", \"dem_nonviral.zip\", 463630510)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_933becc2-b557-48ec-ba38-924fc6cc68d3\", \"dem_viral.zip\", 463630450)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('/content/rep_nonviral.zip')\n",
        "files.download('/content/dem_nonviral.zip')\n",
        "files.download('/content/dem_viral.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "gpt2_fine_tune_tweet_gen",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}